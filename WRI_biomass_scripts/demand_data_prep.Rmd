---
title: "Demand Side Data Preparation"
author: "Henry Strecker"
date: "January 2024"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(readxl)
library(janitor)

# Henry's google drive filepath:
#googleDrivefp <- 'G:/.shortcut-targets-by-id/1ZAqlnUns9gmR-USBe5KtSssVU_DgI5Sw/WRI_biomass/'

googleDrivefp <- '/Users/grace/Library/CloudStorage/GoogleDrive-gracecwu@ucsb.edu/My Drive/Research_Projects/WRI_biomass/'
```


## Joining county names and fips, parsing state and county
```{r}
zone_mapping <- read_xlsx(file.path(googleDrivefp, 'RIO_data/PreliminaryResults/zone mapping.xlsx'))
county_zone <- zone_mapping[1:4]
county_fips <- zone_mapping[8:9] %>% rename(county = name) %>% drop_na()

# Here all of the counties have been joined with their appropriate fips
zone_mapped <- left_join(county_zone, county_fips, by = 'county') %>%
  separate(county, c("county", "state"), sep = ", ") %>%
  clean_names() %>%
  select(fips, county, state, zone, sqmi, households_2010_complete_count) %>%
  filter(!state %in% c('puerto rico', 'quebec (state)')) # Filter out regions with zero sqmi

# Counties that have area in multiple zones with the count of zones they're contained in
county_zone_repeats <- data.frame(table(zone_mapped$county)[table(zone_mapped$county)>1])

# Create and save data for counties that span multiple zones
overlapped <- zone_mapped[zone_mapped$county %in% county_zone_repeats$Var1,] %>% arrange(county)
#write.csv(overlapped, 'C:/Users/Hank1/Documents/BREN/WRI_biomass/WRI_biomass_scripts/county_zone_overlap.csv')
```

## Generating zone overlap proportions for both counties and states
```{r}
# Get values for total areas and overlapping areas
state_areas <- zone_mapped %>% group_by(state) %>% summarize_at('sqmi', sum)
county_areas <- zone_mapped %>% group_by(state, county) %>% summarize_at('sqmi', sum)
state_zone_overlap_sum <- zone_mapped %>% group_by(state, zone) %>% summarize_at('sqmi', sum)

# Initialize lists to be filled with area overlap percentages
county_zone_overlap_prop <- c()
state_zone_overlap_prop <- c()

for (i in 1:dim(zone_mapped)[1]){
  # Save current iteration values for use below
  current_county = zone_mapped$county[i]
  current_state = zone_mapped$state[i]
  current_zone = zone_mapped$zone[i]
  
  # Divide county area in current zone by the corresponding county's total area
  county_zone_overlap_prop <- c(county_zone_overlap_prop, 
                                zone_mapped$sqmi[i]/filter(county_areas, (state == current_state) & (county == current_county))$sqmi)
  # Divide state area in the current zone by the corresponding state's total area
  state_zone_overlap_prop <- c(state_zone_overlap_prop, 
                               filter(state_zone_overlap_sum, (state == current_state) & (zone == current_zone))$sqmi/filter(state_areas, state == current_state)$sqmi)
}

# Write proportion data to new variables
zone_mapped <- zone_mapped %>%
  mutate(county_area_prop = county_zone_overlap_prop,
         state_area_prop = state_zone_overlap_prop)

# Add Loving, Texas because it was missing
zone_mapped <- rbind(zone_mapped, data.frame(fips = 48301, county = 'loving', state = 'texas', zone = 'texas_emm', sqmi = 669, 
                                             households_2010_complete_count = 40, county_area_prop = 1, state_area_prop = 0.7742165)) %>%
  filter(!fips %in% c(51620, 51770, 51515, 51760, 51600, 24510, 29510)) # Remove rows that are duplicates in the form of consolidated city-counties

# https://en.wikipedia.org/wiki/County_(United_States)#Consolidated_city-counties

# Write output of zone mapped if it gets updated
#write.csv(zone_mapped, file.path('G:/.shortcut-targets-by-id/1ZAqlnUns9gmR-USBe5KtSssVU_DgI5Sw/WRI_biomass/Downscaling_biomass/intermediateFiles/zone_mapped.csv'), row.names = FALSE)

# Checks that every unique county has a proportion that adds up to 1
unique(zone_mapped %>% group_by(state, county) %>% summarize_at('county_area_prop', sum) %>% arrange(-county_area_prop) %>% ungroup() %>% select(county_area_prop))
# If you want to check at the state level, compare values of state_areas, state_zone_overlap_sum, and zone_mapped
```
## Below update the biomass feedstocks and categories based on the new v2 form of the csv

## Categorizing direct flows energy categories and converting units
```{r}
# Read in demand and category data
commodity_use <- read.csv(file.path(googleDrivefp, '/RIO_data/FinalResults_June25/commodity_potential.csv')) # New file here only has 2021, 2035, 2050 instead of every ten years like we had before
biomass_feedstocks <- read.csv(file.path(googleDrivefp, 'Downscaling_biomass/intermediateFiles/biomassFeedstocksAndCategories_byScenario_v3.csv'))

# Select only feedstocks we're interested in and add category variable
commodity_use <- commodity_use %>%
  filter(commodity %in% unique(biomass_feedstocks$feedstock)) %>%
  left_join(biomass_feedstocks %>% select(commodity = feedstock, category), by = 'commodity')

# Create columns to categorize feed stocks for use in converting GWh or hectotonnes to tons
commodity_use <- commodity_use %>%
  mutate(
    energy_category = case_when( # Potential for change here based on updates made to broader categories
      category == 'Woody purpose-grown energy crops' | category == 'Forestry waste and residues' ~ 'Forestry',
      commodity == 'landfill gas' ~ 'Landfill gas',
      TRUE ~ 'Other'),  # Default value if none of the conditions match
    tons = case_when(
      unit == 'hectotonne' ~ value*100, # First convert hectotonnes
      energy_category == 'Forestry' ~ value*3600/19, # Then convert forestry category
      energy_category == 'Landfill gas' ~ value*3600/26.1, # Then convert landfill gas commodity
      TRUE ~ value*3600/15 # Convert the remaining feed stocks
    )
  ) %>%
  filter(type == 'actual') # Filter out all potential values, they're not necessary

```

## Final step to join zone demand and feedstocks
```{r}
# Average number of commodity rows per zone
avg_commodities <- mean(table(commodity_use$zone))
# Number of counties in the US
total_counties <- dim(zone_mapped)[1]
# Estimated number of rows in direct_flow_county, note that results will be higher because of counties appearing in multiple zones - expect ~15% increase
projected_rows <- avg_commodities * total_counties * 1.15

direct_flow_county <- merge(zone_mapped, commodity_use, by='zone') %>%
  select(-c('households_2010_complete_count', 'unit', 'sqmi', 'value', 'type')) %>% # Remove unnecessary columns to reduce file size
  filter(year %in% c(2035, 2050), # Remove 2021, we don't need it for results
         !tons == 0) %>% # Remove rows with 0 tons of demand
  rename(name = commodity)
  
# Write output to drive
write.csv(direct_flow_county, file.path(googleDrivefp, 'Downscaling_biomass/intermediateFiles/commodity_potential_county_level_v2.csv'), row.names = FALSE)
```
